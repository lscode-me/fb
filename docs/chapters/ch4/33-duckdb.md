# –ì–ª–∞–≤–∞ 33. DuckDB: SQL –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤

## –í–≤–µ–¥–µ–Ω–∏–µ

**DuckDB** ‚Äî –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö, —Ä–∞–±–æ—Ç–∞—é—â–∞—è –ª–æ–∫–∞–ª—å–Ω–æ –∏ –ø–æ–∑–≤–æ–ª—è—é—â–∞—è –≤—ã–ø–æ–ª–Ω—è—Ç—å SQL-–∑–∞–ø—Ä–æ—Å—ã –Ω–∞–ø—Ä—è–º—É—é –∫ CSV, Parquet, JSON –∏ –¥—Ä—É–≥–∏–º —Ñ–∞–π–ª–∞–º –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏. –ò–¥–µ–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è data engineering –∏ ad-hoc –∞–Ω–∞–ª–∏–∑–∞.

---

## 33.1 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# Python
pip install duckdb

# CLI
brew install duckdb      # macOS
# –∏–ª–∏ —Å–∫–∞—á–∞—Ç—å —Å https://duckdb.org
```

### –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º

```bash
$ duckdb
D SELECT 'Hello, DuckDB!' as greeting;
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    greeting     ‚îÇ
‚îÇ     varchar     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Hello, DuckDB!  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 33.2 –ó–∞–ø—Ä–æ—Å—ã –∫ —Ñ–∞–π–ª–∞–º

### CSV

```sql
-- –ß—Ç–µ–Ω–∏–µ CSV
SELECT * FROM 'data.csv';

-- –° —è–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
SELECT * FROM read_csv('data.csv',
    header = true,
    delim = ',',
    quote = '"',
    columns = {'name': 'VARCHAR', 'age': 'INTEGER'}
);

-- –ß—Ç–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
SELECT * FROM 'data/*.csv';
SELECT * FROM read_csv(['file1.csv', 'file2.csv']);

-- –ó–∞–ø–∏—Å—å –≤ CSV
COPY (SELECT * FROM my_table) TO 'output.csv' (HEADER, DELIMITER ',');
```

### Parquet

```sql
-- –ß—Ç–µ–Ω–∏–µ Parquet
SELECT * FROM 'data.parquet';

-- –ß—Ç–µ–Ω–∏–µ –ø–∞–ø–∫–∏ —Å partition
SELECT * FROM 'data/year=*/month=*/*.parquet';

-- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
SELECT * FROM parquet_metadata('data.parquet');
SELECT * FROM parquet_schema('data.parquet');

-- –ó–∞–ø–∏—Å—å –≤ Parquet
COPY (SELECT * FROM my_table) TO 'output.parquet' (FORMAT PARQUET);
```

### JSON

```sql
-- JSON Lines (–∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –æ–±—ä–µ–∫—Ç)
SELECT * FROM 'data.jsonl';

-- JSON –º–∞—Å—Å–∏–≤
SELECT * FROM read_json('data.json', format = 'array');

-- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
SELECT 
    json->>'name' as name,
    json->'address'->>'city' as city
FROM read_json('data.json');
```

---

## 33.3 Python –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
import duckdb

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (in-memory)
con = duckdb.connect()

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
result = con.execute("SELECT 42 as answer").fetchall()
# [(42,)]

# –ü–æ–ª—É—á–µ–Ω–∏–µ DataFrame
df = con.execute("SELECT * FROM 'data.csv'").df()

# –ó–∞–ø—Ä–æ—Å –∫ DataFrame
import pandas as pd
my_df = pd.DataFrame({'a': [1, 2, 3], 'b': ['x', 'y', 'z']})
result = con.execute("SELECT * FROM my_df WHERE a > 1").df()
```

### –ë–µ–∑ —è–≤–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è

```python
import duckdb

# –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å
df = duckdb.query("SELECT * FROM 'data.parquet' LIMIT 10").df()

# SQL –∫ pandas DataFrame
import pandas as pd
df = pd.read_csv('data.csv')
result = duckdb.query("SELECT name, AVG(age) FROM df GROUP BY name").df()
```

### –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä

```python
import duckdb

with duckdb.connect('my_database.db') as con:
    con.execute("CREATE TABLE users AS SELECT * FROM 'users.csv'")
    con.execute("INSERT INTO users VALUES ('Alice', 30)")
    result = con.execute("SELECT * FROM users").df()
```

---

## 33.4 –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏

### –û–∫–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

```sql
SELECT 
    name,
    department,
    salary,
    AVG(salary) OVER (PARTITION BY department) as dept_avg,
    RANK() OVER (PARTITION BY department ORDER BY salary DESC) as rank
FROM 'employees.csv';
```

### –ê–≥—Ä–µ–≥–∞—Ü–∏—è

```sql
-- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞
SELECT 
    category,
    COUNT(*) as count,
    SUM(amount) as total,
    AVG(amount) as average,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount) as median
FROM 'sales.csv'
GROUP BY category;

-- ROLLUP
SELECT 
    COALESCE(region, 'Total') as region,
    COALESCE(category, 'All') as category,
    SUM(sales) as total_sales
FROM 'sales.csv'
GROUP BY ROLLUP(region, category);
```

### Pivot / Unpivot

```sql
-- Pivot
PIVOT 'sales.csv' 
ON category 
USING SUM(amount) 
GROUP BY region;

-- Unpivot
UNPIVOT 'wide_data.csv' 
ON col1, col2, col3 
INTO NAME variable VALUE value;
```

---

## 33.5 –†–∞–±–æ—Ç–∞ —Å –±–æ–ª—å—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏

### –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞

```python
# DuckDB —á–∏—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏ —Å—Ç—Ä–æ–∫–∏
result = duckdb.query("""
    SELECT name, age 
    FROM 'huge_file.parquet' 
    WHERE age > 30 
    LIMIT 100
""").df()
# –ù–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ—Å—å —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç—å!
```

### –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ

```sql
-- DuckDB –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ —è–¥—Ä–∞
SELECT COUNT(*) FROM 'big_data/*.parquet';
```

### Streaming —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```python
# –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ø–∞–º—è—Ç—å
con = duckdb.connect()
result = con.execute("SELECT * FROM 'huge.csv'")

while batch := result.fetchmany(10000):
    process_batch(batch)
```

---

## 33.6 –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö

```sql
-- –í CSV
COPY (SELECT * FROM my_query) TO 'output.csv' (HEADER);

-- –í Parquet
COPY (SELECT * FROM my_query) TO 'output.parquet' (FORMAT PARQUET);

-- –í JSON
COPY (SELECT * FROM my_query) TO 'output.json' (FORMAT JSON);

-- Partitioned –≤—ã–≤–æ–¥
COPY (SELECT * FROM sales) 
TO 'output' 
(FORMAT PARQUET, PARTITION_BY (year, month));
```

---

## 33.7 –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### –ê–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤

```sql
-- –ü–∞—Ä—Å–∏–Ω–≥ Apache –ª–æ–≥–æ–≤
SELECT 
    regexp_extract(line, '^(\S+)', 1) as ip,
    regexp_extract(line, '"(\w+) ', 1) as method,
    regexp_extract(line, '" (\d+) ', 1)::int as status,
    COUNT(*) as requests
FROM read_csv('access.log', columns = {'line': 'VARCHAR'}, header = false)
GROUP BY ip, method, status
ORDER BY requests DESC
LIMIT 20;
```

### ETL –ø–∞–π–ø–ª–∞–π–Ω

```python
import duckdb

# –ß–∏—Ç–∞–µ–º –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
con = duckdb.connect()

con.execute("""
    CREATE TABLE merged AS
    SELECT a.*, b.category 
    FROM 'transactions/*.csv' a
    JOIN 'categories.parquet' b ON a.category_id = b.id
    WHERE a.date >= '2024-01-01'
""")

# –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
con.execute("""
    COPY (
        SELECT 
            category,
            DATE_TRUNC('month', date) as month,
            SUM(amount) as total
        FROM merged
        GROUP BY category, month
    ) TO 'monthly_summary.parquet' (FORMAT PARQUET)
""")
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤

```sql
-- –ù–∞–π—Ç–∏ —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –¥–≤—É–º—è CSV
SELECT * FROM 'old.csv'
EXCEPT
SELECT * FROM 'new.csv';

-- –ù–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
SELECT * FROM 'new.csv'
EXCEPT  
SELECT * FROM 'old.csv';
```

---

## 33.8 DuckDB vs –¥—Ä—É–≥–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã

| –ó–∞–¥–∞—á–∞ | DuckDB | pandas | SQLite | Spark |
|--------|--------|--------|--------|-------|
| –ß–∏—Ç–∞—Ç—å Parquet | ‚úÖ Native | ‚úÖ pyarrow | ‚ùå | ‚úÖ |
| –ß–∏—Ç–∞—Ç—å –æ–≥—Ä–æ–º–Ω—ã–π CSV | ‚úÖ Streaming | ‚ö†Ô∏è –ü–∞–º—è—Ç—å | ‚ùå Import | ‚úÖ |
| SQL | ‚úÖ –ü–æ–ª–Ω—ã–π | ‚ö†Ô∏è pandasql | ‚úÖ | ‚úÖ |
| –°–∫–æ—Ä–æ—Å—Ç—å | üöÄ –ë—ã—Å—Ç—Ä–æ | üê¢ –ú–µ–¥–ª–µ–Ω–Ω–æ | üê¢ –ú–µ–¥–ª–µ–Ω–Ω–æ | üöÄ –†–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ |
| –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ | –ú–∏–Ω–∏–º—É–º | –ú–Ω–æ–≥–æ | –ú–∏–Ω–∏–º—É–º | –ú–Ω–æ–≥–æ |
| –†–∞–∑–≤—ë—Ä—Ç—ã–≤–∞–Ω–∏–µ | –õ–æ–∫–∞–ª—å–Ω–æ | –õ–æ–∫–∞–ª—å–Ω–æ | –õ–æ–∫–∞–ª—å–Ω–æ | –ö–ª–∞—Å—Ç–µ—Ä |

---

## –†–µ–∑—é–º–µ

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|----------------|----------|
| –¢–∏–ø | –í—Å—Ç—Ä–∞–∏–≤–∞–µ–º–∞—è OLAP –±–∞–∑–∞ |
| –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –ë–î | `.duckdb`, `.db` |
| –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤ | CSV, Parquet, JSON, Excel |
| Python API | `pip install duckdb` |
| CLI | `duckdb` |
| –õ–∏—Ü–µ–Ω–∑–∏—è | MIT |

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DuckDB:**

- –ê–Ω–∞–ª–∏–∑ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (CSV, Parquet)
- ETL –Ω–∞ –æ–¥–Ω–æ–π –º–∞—à–∏–Ω–µ
- –ó–∞–º–µ–Ω–∞ pandas –¥–ª—è SQL-–∑–∞–ø—Ä–æ—Å–æ–≤
- –ü—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ—Ö–æ–¥–æ–º –Ω–∞ Spark


??? question "–£–ø—Ä–∞–∂–Ω–µ–Ω–∏—è"
    **–ó–∞–¥–∞–Ω–∏–µ 1.** –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV-—Ñ–∞–π–ª –≤ DuckDB –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ GROUP BY —Å –∞–≥—Ä–µ–≥–∞—Ü–∏–µ–π. –°—Ä–∞–≤–Ω–∏—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å —Å `pandas.groupby()`.
    
    **–ó–∞–¥–∞–Ω–∏–µ 2.** –í—ã–ø–æ–ª–Ω–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º Parquet-—Ñ–∞–π–ª–∞–º —á–µ—Ä–µ–∑ glob: `SELECT * FROM 'data/2024/*/*.parquet'`. –†–∞–±–æ—Ç–∞–µ—Ç –ª–∏ predicate pushdown?
    
    **–ó–∞–¥–∞–Ω–∏–µ 3.** –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π—Ç–µ CSV –≤ Parquet –æ–¥–Ω–æ–π SQL-–∫–æ–º–∞–Ω–¥–æ–π DuckDB: `COPY (SELECT * FROM 'input.csv') TO 'output.parquet' (FORMAT PARQUET)`. –°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–∞–∑–º–µ—Ä.

---

## Troubleshooting: —Ç–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –ß–∞—Å—Ç–∏ IV

!!! bug "Pipeline –∑–∞–≤–∏—Å–∞–µ—Ç (deadlock)"
    ```bash
    # –ó–∞–≤–∏—Å–∞–µ—Ç, –µ—Å–ª–∏ fifo –Ω–∏–∫—Ç–æ –Ω–µ —á–∏—Ç–∞–µ—Ç:
    echo "data" > my_fifo &
    # ( –∏ –Ω–∞–æ–±–æ—Ä–æ—Ç ‚Äî cat my_fifo –∑–∞–≤–∏—Å–Ω–µ—Ç, –µ—Å–ª–∏ –Ω–∏–∫—Ç–æ –Ω–µ –ø–∏—à–µ—Ç )
    ```
    –ü–∞–π–ø—ã –∏–º–µ—é—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –±—É—Ñ–µ—Ä (~64 KB –≤ Linux). –ï—Å–ª–∏ —á–∏—Ç–∞—Ç–µ–ª—å –Ω–µ –ø–æ—Ç—Ä–µ–±–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ, –ø–∏—Å–∞—Ç–µ–ª—å –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è. –†–µ—à–µ–Ω–∏–µ: –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –æ–±–µ —Å—Ç–æ—Ä–æ–Ω—ã –ø–∞–π–ø–ª–∞–π–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `timeout`.

!!! bug "Out of Memory –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–æ–ª—å—à–æ–≥–æ —Ñ–∞–π–ª–∞"
    ```python
    # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ ‚Äî –≤–µ—Å—å —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç–∏:
    data = open('10gb.csv').read()
    
    # –ü—Ä–∞–≤–∏–ª—å–Ω–æ ‚Äî –ø–æ—Å—Ç—Ä–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞:
    with open('10gb.csv') as f:
        for line in f:  # –∏—Ç–µ—Ä–∞—Ç–æ—Ä, –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å—ë —Å—Ä–∞–∑—É
            process(line)
    
    # –ï—â—ë –ª—É—á—à–µ ‚Äî DuckDB / Polars (–ª–µ–Ω–∏–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è):
    import duckdb
    duckdb.sql("SELECT count(*) FROM '10gb.csv'")
    ```

!!! bug "grep/sed –≤–µ–¥—É—Ç —Å–µ–±—è —Å—Ç—Ä–∞–Ω–Ω–æ —Å –±–∏–Ω–∞—Ä–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏"
    ```bash
    # grep –º–æ–∂–µ—Ç —Å–∫–∞–∑–∞—Ç—å "Binary file matches":
    grep -a "pattern" binary_file  # -a = treat as text
    
    # –ò–ª–∏ —Ä–∞–±–æ—Ç–∞–π—Ç–µ —Å hex:
    xxd binary_file | grep "pattern"
    ```
    Coreutils –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ—Ç–æ–∫–∏. –î–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `hexdump`, `xxd`, `binwalk`.

!!! bug "–ö–æ–¥–∏—Ä–æ–≤–∫–∞ –≤ pipe –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"
    ```bash
    # –í —Ç–µ—Ä–º–∏–Ω–∞–ª–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∞ –≤ pipe ‚Äî –∫—Ä–∞–∫–æ–∑—è–±—Ä—ã:
    python script.py | less  # PYTHONIOENCODING –º–æ–∂–µ—Ç –±—ã—Ç—å ASCII –≤ pipe!
    
    # –†–µ—à–µ–Ω–∏–µ:
    export PYTHONIOENCODING=utf-8
    # –∏–ª–∏:
    python -u script.py | less  # -u = unbuffered
    ```
    –í pipe Python –º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å ASCII –≤–º–µ—Å—Ç–æ UTF-8. –ó–∞–¥–∞–π—Ç–µ `PYTHONIOENCODING=utf-8`.

!!! tip "–°–ª–µ–¥—É—é—â–∞—è –≥–ª–∞–≤–∞"
    –ó–∞–≤–µ—Ä—à–∏–ª–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —á–∞—Å—Ç—å. –¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ–π–¥—ë–º –∫ **–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ö—Ä–∞–Ω–µ–Ω–∏—è** ‚Äî –æ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –¥–∏—Å–∫–æ–≤ –¥–æ —Ñ–∞–π–ª–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º ‚Üí [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª–µ–π](../ch5/34-architecture.md)
