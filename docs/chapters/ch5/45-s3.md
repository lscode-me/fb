# Глава 45. S3 — объектное хранилище

## Введение

**Amazon S3** (Simple Storage Service) — это объектное хранилище, ставшее стандартом де-факто для облачного хранения файлов. Многие провайдеры предлагают S3-совместимые API.

---

## 45.1 Объектное хранилище vs Файловая система

```
Файловая система:                 Объектное хранилище:
┌────────────────────┐            ┌────────────────────┐
│  /                 │            │  Bucket            │
│  ├── home/         │            │  ├── photos/2024/  │ ← prefix (не папка!)
│  │   └── user/     │            │  │   └── img.jpg   │
│  │       └── file  │            │  └── logs/app.log  │
│  └── var/          │            └────────────────────┘
│      └── log/      │
└────────────────────┘

Файловая система:                 S3:
- Иерархия каталогов              - Плоское пространство ключей
- Изменение файлов (seek, write)  - Замена объекта целиком
- Метаданные в inode              - Метаданные HTTP headers
- POSIX семантика                 - REST API
- Атомарные операции              - Eventually consistent (иногда)
```

---

## 45.2 Концепции S3

### Bucket (корзина)

```
- Глобально уникальное имя
- Регион (us-east-1, eu-west-1, etc.)
- Настройки доступа, версионирование, шифрование

Примеры имён:
  my-company-backups
  app-logs-2024
  static.example.com
```

### Object (объект)

```
Объект = Ключ + Данные + Метаданные

Ключ:  photos/2024/01/img001.jpg   (до 1024 байт UTF-8)
Данные: бинарное содержимое       (до 5 TB)
Метаданные:
  - Content-Type: image/jpeg
  - Content-Length: 1048576
  - x-amz-meta-author: John Doe   (пользовательские)
```

### Prefix (префикс)

```
S3 не имеет настоящих папок!
"photos/2024/" — это просто префикс ключа

Но можно "симулировать" папки:
s3://bucket/photos/
s3://bucket/photos/2024/
s3://bucket/photos/2024/01/
```

---

## 45.3 AWS CLI

### Установка и настройка

```bash
# Установка
pip install awscli
# или
brew install awscli

# Настройка
aws configure
# AWS Access Key ID: AKIA...
# AWS Secret Access Key: wJalr...
# Default region: eu-west-1
# Default output format: json

# Проверка
aws sts get-caller-identity
```

### Основные операции

```bash
# Список бакетов
aws s3 ls

# Список объектов
aws s3 ls s3://bucket-name/
aws s3 ls s3://bucket-name/prefix/

# Копирование локальный → S3
aws s3 cp file.txt s3://bucket/path/file.txt

# Копирование S3 → локальный
aws s3 cp s3://bucket/path/file.txt ./

# Синхронизация (как rsync)
aws s3 sync ./local/ s3://bucket/remote/
aws s3 sync s3://bucket/remote/ ./local/

# С удалением лишних файлов
aws s3 sync --delete ./local/ s3://bucket/remote/

# Удаление
aws s3 rm s3://bucket/file.txt
aws s3 rm --recursive s3://bucket/prefix/
```

### Создание и удаление бакетов

```bash
# Создать бакет
aws s3 mb s3://my-new-bucket

# В определённом регионе
aws s3 mb s3://my-bucket --region eu-central-1

# Удалить пустой бакет
aws s3 rb s3://my-bucket

# Удалить бакет со всем содержимым
aws s3 rb s3://my-bucket --force
```

---

## 45.4 S3 API (boto3 для Python)

### Базовые операции

```python
import boto3

# Клиент
s3 = boto3.client('s3')

# Список бакетов
response = s3.list_buckets()
for bucket in response['Buckets']:
    print(bucket['Name'])

# Загрузка файла
s3.upload_file('local.txt', 'bucket-name', 'remote/path/file.txt')

# С метаданными
s3.upload_file(
    'image.jpg', 'bucket', 'photos/img.jpg',
    ExtraArgs={
        'ContentType': 'image/jpeg',
        'Metadata': {'author': 'John'}
    }
)

# Скачивание
s3.download_file('bucket', 'remote/file.txt', 'local.txt')

# Чтение напрямую в память
obj = s3.get_object(Bucket='bucket', Key='file.txt')
content = obj['Body'].read().decode('utf-8')
```

### Работа с большими файлами

```python
# Multipart upload для файлов > 5GB
from boto3.s3.transfer import TransferConfig

config = TransferConfig(
    multipart_threshold=8 * 1024 * 1024,  # 8MB
    max_concurrency=10,
    multipart_chunksize=8 * 1024 * 1024
)

s3.upload_file('large.zip', 'bucket', 'large.zip', Config=config)
```

### Presigned URLs

```python
# Временная ссылка для скачивания (действует 1 час)
url = s3.generate_presigned_url(
    'get_object',
    Params={'Bucket': 'bucket', 'Key': 'file.txt'},
    ExpiresIn=3600
)
print(url)

# Для загрузки
url = s3.generate_presigned_url(
    'put_object',
    Params={'Bucket': 'bucket', 'Key': 'uploads/new.txt'},
    ExpiresIn=3600
)
# Клиент загружает: curl -X PUT -T file.txt "$url"
```

---

## 45.5 S3 Select

```python
# SQL-запросы к данным в S3 (без скачивания всего файла)

response = s3.select_object_content(
    Bucket='bucket',
    Key='data.csv',
    ExpressionType='SQL',
    Expression="SELECT * FROM s3object WHERE age > 30",
    InputSerialization={'CSV': {'FileHeaderInfo': 'USE'}},
    OutputSerialization={'JSON': {}}
)

for event in response['Payload']:
    if 'Records' in event:
        print(event['Records']['Payload'].decode())
```

---

## 45.6 Версионирование

```bash
# Включить версионирование
aws s3api put-bucket-versioning \
    --bucket my-bucket \
    --versioning-configuration Status=Enabled

# Список версий объекта
aws s3api list-object-versions --bucket my-bucket --prefix file.txt

# Получить конкретную версию
aws s3api get-object \
    --bucket my-bucket \
    --key file.txt \
    --version-id "abc123" \
    output.txt

# Восстановить старую версию (копировать поверх)
aws s3api copy-object \
    --bucket my-bucket \
    --key file.txt \
    --copy-source "my-bucket/file.txt?versionId=abc123"
```

---

## 45.7 Storage Classes

| Класс | Описание | Цена хранения | Доступ |
|-------|----------|---------------|--------|
| STANDARD | Часто используемые данные | $$$ | Мгновенный |
| STANDARD_IA | Редкий доступ | $$ | Мгновенный |
| ONE_ZONE_IA | Один AZ, редкий доступ | $ | Мгновенный |
| GLACIER | Архив | ¢ | Минуты-часы |
| GLACIER_DEEP | Глубокий архив | ¢/10 | 12-48 часов |
| INTELLIGENT_TIERING | Автоматический | Авто | Мгновенный |

```bash
# Загрузка с классом хранения
aws s3 cp file.zip s3://bucket/ --storage-class GLACIER

# Изменение класса
aws s3 cp s3://bucket/file.zip s3://bucket/file.zip \
    --storage-class STANDARD_IA
```

---

## 45.8 S3-совместимые сервисы

### MinIO (self-hosted S3)

```bash
# Запуск MinIO
docker run -p 9000:9000 -p 9001:9001 \
    -e MINIO_ROOT_USER=admin \
    -e MINIO_ROOT_PASSWORD=password \
    minio/minio server /data --console-address ":9001"

# Использование с aws cli
aws --endpoint-url http://localhost:9000 s3 ls
```

### Другие провайдеры

```
- DigitalOcean Spaces
- Backblaze B2
- Cloudflare R2
- Yandex Object Storage
- Selectel S3
```

```bash
# Пример: Backblaze B2
aws --endpoint-url https://s3.us-west-002.backblazeb2.com s3 ls
```

---

## 45.9 Монтирование S3

### s3fs-fuse

```bash
# Установка
apt install s3fs

# Credentials
echo "ACCESS_KEY:SECRET_KEY" > ~/.passwd-s3fs
chmod 600 ~/.passwd-s3fs

# Монтирование
s3fs mybucket /mnt/s3 -o passwd_file=~/.passwd-s3fs

# С кэшированием
s3fs mybucket /mnt/s3 -o passwd_file=~/.passwd-s3fs \
    -o use_cache=/tmp/s3cache
```

### goofys (быстрее s3fs)

```bash
# Установка
go install github.com/kahing/goofys@latest

# Монтирование
goofys mybucket /mnt/s3
```

---

## 45.10 Best Practices

### Именование ключей

```bash
# Хорошо: распределённые префиксы
s3://bucket/2024/01/15/file-abc123.log
s3://bucket/2024/01/15/file-def456.log

# Плохо: одинаковые префиксы (горячие точки)
s3://bucket/logs/file1.log
s3://bucket/logs/file2.log
```

### Безопасность

```json
// Bucket policy — минимальные права
{
  "Effect": "Allow",
  "Principal": {"AWS": "arn:aws:iam::123456789:role/MyRole"},
  "Action": ["s3:GetObject"],
  "Resource": "arn:aws:s3:::bucket/*"
}
```

---

## Резюме

```
S3 = Объектное хранилище с REST API
   = Бесконечно масштабируемое
   = Durability 99.999999999% (11 девяток)

Ключевые команды:
  aws s3 cp  — копирование
  aws s3 sync — синхронизация
  aws s3 ls  — просмотр
  aws s3 rm  — удаление

Использование:
  - Бэкапы
  - Статические сайты
  - Data Lake
  - Логи
  - Медиа файлы
```

??? question "Упражнения"
    **Задание 1.** Установите MinIO локально (`docker run minio/minio server /data`). Создайте bucket, загрузите файл через `aws s3 cp` с endpoint override.
    
    **Задание 2.** Напишите Python-скрипт с `boto3`: загрузите файл в S3, создайте presigned URL с TTL 5 минут, скачайте по этому URL.
    
    **Задание 3.** Настройте lifecycle policy: объекты старше 30 дней переносятся в Glacier (или удаляются в MinIO). Проверьте через `aws s3api`.
